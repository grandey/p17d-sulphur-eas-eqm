#+TITLE: p17d-sulphur-eas-eqm/data_management.org
#+AUTHOR: Benjamin S. Grandey
#+OPTIONS: ^:nil

** Data management

*** Size of atmosphere-ocean (B) output
Due to the large size of the atmospheric downscaling data and the ocean data, each coupled atmosphere-ocean simulation produces approximately 300 GB/decade (3 TB/century). Of this, approximately 120 GB is atmospheric downscaling data, 130 GB is monthly ocean data, and 50 GB is other data.

By gzipping the data, the size of the atmospheric downscaling data files can be reduced by 15% and the monthly ocean data files by almost 60%. Hence, gzipping should reduce the overall data size to approximately 200 GB/decade (2 TB/century).

In order to further reduce the storage requirements, the downscaling and ocean data from the first four decades can be deleted (see below).

*** Saving a copy of the output data to Newton
On Cheyenne, a copy of the case directory for each simulation will be rsynced to the archive directory, e.g.:

#+BEGIN_SRC
CASENAME=p17d_f_2000
ARCHIVE_DIR=/glade/scratch/bgrandey/archive
rsync -av /glade/u/home/bgrandey/cesm1_2_2_1_cases/$CASENAME $ARCHIVE_DIR/$CASENAME/arch_case/
#+END_SRC

On Cheyenne, the NetCDF files in the archive directory will be gzipped:

#+BEGIN_SRC
for f in $ARCHIVE_DIR/$CASENAME/*/*/*.nc; do if [ -f $f ]; then echo "Gzipping $f"; gzip -f $f; fi; done
#+END_SRC

For the atmosphere-ocean simulations, the downscaling and monthly ocean data from the first four decades (actually 39 years) can be deleted:

#+BEGIN_SRC
rm -f $ARCHIVE_DIR/$CASENAME/atm/hist/$CASENAME.cam.h1.00[0123]?-*.nc.gz
rm -f $ARCHIVE_DIR/$CASENAME/lnd/hist/$CASENAME.clm2.h1.00[0123]?-*.nc.gz
rm -f $ARCHIVE_DIR/$CASENAME/ocn/hist/$CASENAME.pop.h.00[0123]?-*.nc.gz
#+END_SRC

A copy of the data will then be rsynced from Cheyenne to Newton:

#+BEGIN_SRC
rsync -avz --progress -e "ssh -p $NEWTON_PORT" $ARCHIVE_DIR/$CASENAME $NEWTON_USER@$NEWTON_IP:/somerset/grandey/data4/acrc/RUN/archive/
#+END_SRC

Transfer speeds are approximately 0.5 MB/s (40 GB/day). The transfer can be sped up by running several rsync tasks concurrently, with each task transferring a subset of the data, e.g.:

#+BEGIN_SRC
rsync -avz --progress -e "ssh -p $NEWTON_PORT" $ARCHIVE_DIR/$CASENAME/atm/hist/$CASENAME.cam.h0.*.nc.gz $NEWTON_USER@$NEWTON_IP:/somerset/grandey/data4/acrc/RUN/archive/$CASENAME/atm/hist/

rsync -avz --progress -e "ssh -p $NEWTON_PORT" $ARCHIVE_DIR/$CASENAME/atm/hist/$CASENAME.cam.h1.0???-0[123]-*.nc.gz $NEWTON_USER@$NEWTON_IP:/somerset/grandey/data4/acrc/RUN/archive/$CASENAME/atm/hist/

rsync -avz --progress -e "ssh -p $NEWTON_PORT" $ARCHIVE_DIR/$CASENAME/ocn/hist/$CASENAME.pop.h.nday1.*.nc.gz $NEWTON_USER@$NEWTON_IP:/somerset/grandey/data4/acrc/RUN/archive/$CASENAME/ocn/hist/

rsync -avz --progress -e "ssh -p $NEWTON_PORT" $ARCHIVE_DIR/$CASENAME/ocn/hist/$CASENAME.pop.h.0???-0[123].nc.gz $NEWTON_USER@$NEWTON_IP:/somerset/grandey/data4/acrc/RUN/archive/$CASENAME/ocn/hist/

for M in lnd ice; do echo $M; rsync -avz --progress -e "ssh -p $NEWTON_PORT" $ARCHIVE_DIR/$CASENAME/$M/hist/$CASENAME.*.nc.gz $NEWTON_USER@$NEWTON_IP:/somerset/grandey/data4/acrc/RUN/archive/$CASENAME/$M/hist/; done
#+END_SRC

*** Converting from time-slice to time-series format
After gunzipping a copy of the atmospheric h0 files on Newton, [[https://github.com/NCAR/PyReshaper][PyReshaper]] (v1.0.1) can be used to convert to time-series format. I have =PyReshaper= installed in a separate =conda= environment:

#+BEGIN_SRC
source activate pyreshaper
#+END_SRC

First, =s2make= is used to generate a specifier file, e.g.:

#+BEGIN_SRC
CASENAME=p17d_f_2000

IN_DIR=/somerset/grandey/data4/acrc/RUN/unzipped/$CASENAME/atm/hist
OUT_DIR=/dhobyghaut/grandey/data5/cesm/s2s/$CASENAME/atm

mkdir -p $OUT_DIR

s2smake \
    --netcdf_format="netcdf4" \
    --compression_level=1 \
    --output_prefix="$OUT_DIR/$CASENAME.cam.h0." \
    --output_suffix=".nc" \
    -m "time" -m "time_bnds" -m "ch4vmr" -m "co2vmr" -m "f11vmr" \
    -m "time_written" -m "n2ovmr" -m "date_written" -m "f12vmr" \
    -m "sol_tsi" -m "nsteph" -m "datesec" -m "ndcur" -m "date" \
    -m "nscur" \
    --specfile=$OUT_DIR/specfile_$CASENAME.s2s \
    $IN_DIR/$CASENAME.cam.h0.????-??.nc
#+END_SRC

(The metadata field information (indicated by =m=) has been copied from some example code Daniel Rothenberg kindly provided.)

Second, =s2run= is run in parallel in order to convert the data to time-series format:

#+BEGIN_SRC
mpirun -n 8 s2srun --verbosity=2 $OUT_DIR/specfile_$CASENAME.s2s
#+END_SRC
 
*** Syncing to local machine for analysis
Data of interest can then be pulled from Newton using rsync.

Prescribed-SST simulation data of interest:

#+BEGIN_SRC
CASENAME_LIST="p17d_f_2000 p17d_f_eas0 p17d_f_eas0b p17d_f_eas0c"
VARIABLE_LIST="FSNTOA FSNTOA_d1 FSNTOAC_d1 SWCF_d1 LWCF CLDHGH TGCLDIWP"
#+END_SRC

Coupled atmosphere-ocean simulation data of interest:

#+BEGIN_SRC
CASENAME_LIST="p17d_b_2000 p17d_b_eas0 p17d_b_eas0b p17d_b_eas0c"
VARIABLE_LIST="TS PRECC PRECL U OMEGA"
#+END_SRC

Rsync command:

#+BEGIN_SRC
for CASENAME in $CASENAME_LIST
do
  for VARIABLE in $VARIABLE_LIST
  do
    rsync -av --progress -e "ssh -p $NEWTON_PORT" \
        $NEWTON_USER@$NEWTON_IP:/dhobyghaut/grandey/data5/cesm/s2s/$CASENAME/atm/$CASENAME.cam.h0.$VARIABLE.nc \
        $HOME/data/projects/p17d_sulphur_eas_eqm/output_timeseries/
  done
done
#+END_SRC

*** Uploading data to Figshare

**** Input data
Archiving emissions data files in input_data_p17d.tar.gz.

**** Output timeseries data
A subset of the atmosphere output NetCDF files have been previously synced to  =$HOME/data/projects/p17d_sulphur_eas_eqm/output_timeseries/= on the local machine (see above). The total size is approximately 14GB.

**** History of Figshare publication
- 2018-04-02 - Starting to upload data. Entering metadata. Title: Data for "The equilibrium climate response to sulfur dioxide and carbonaceous aerosol emissions from East and Southeast Asia". Reserving DOI: https://doi.org/10.6084/m9.figshare.6072887. Not yet published.
- 2018-04-03 - Re-uploading =p17d_b_eas0c.cam.h0.OMEGA.nc= (following failed upload). Publishing v1: https://doi.org/10.6084/m9.figshare.6072887.v1.
